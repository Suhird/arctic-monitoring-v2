{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Model Training\n",
    "\n",
    "Train Arctic ice classification models interactively in this notebook.\n",
    "\n",
    "This notebook allows you to:\n",
    "- Train models with custom parameters\n",
    "- Monitor training in real-time\n",
    "- Visualize training progress\n",
    "- Experiment with hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.path.append('../training')\n",
    "sys.path.append('../data')\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Training configuration\n",
    "CONFIG = {\n",
    "    'data_dir': '../data/processed',\n",
    "    'batch_size': 16,  # Reduce if out of memory\n",
    "    'num_epochs': 10,  # Start with fewer epochs for testing\n",
    "    'learning_rate': 0.001,\n",
    "    'num_classes': 3,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'save_dir': '../models',\n",
    "}\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Create save directory\n",
    "os.makedirs(CONFIG['save_dir'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class IceDataset(Dataset):\n",
    "    \"\"\"Dataset for ice imagery\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir, split='train'):\n",
    "        self.data_dir = f\"{data_dir}/{split}\"\n",
    "        self.image_dir = f\"{self.data_dir}/images\"\n",
    "        self.label_dir = f\"{self.data_dir}/labels\"\n",
    "        \n",
    "        # Get all samples\n",
    "        self.samples = sorted([f for f in os.listdir(self.image_dir) if f.endswith('.npy')])\n",
    "        \n",
    "        print(f\"Loaded {len(self.samples)} {split} samples\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample_name = self.samples[idx]\n",
    "        \n",
    "        # Load image\n",
    "        image = np.load(f\"{self.image_dir}/{sample_name}\")\n",
    "        image = torch.from_numpy(image).permute(2, 0, 1).float()\n",
    "        \n",
    "        # Load label\n",
    "        label = np.load(f\"{self.label_dir}/{sample_name}\")\n",
    "        \n",
    "        # Get dominant class\n",
    "        unique, counts = np.unique(label, return_counts=True)\n",
    "        dominant_class = unique[np.argmax(counts)]\n",
    "        \n",
    "        return image, torch.tensor(dominant_class, dtype=torch.long)\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = IceDataset(CONFIG['data_dir'], 'train')\n",
    "val_dataset = IceDataset(CONFIG['data_dir'], 'val')\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], \n",
    "                         shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], \n",
    "                       shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"\\nTrain batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class IceClassifier(nn.Module):\n",
    "    \"\"\"ResNet50-based ice classifier\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=3, pretrained=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load ResNet50\n",
    "        self.backbone = models.resnet50(pretrained=pretrained)\n",
    "        \n",
    "        # Freeze early layers\n",
    "        for param in list(self.backbone.parameters())[:-30]:\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Replace classifier\n",
    "        in_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# Create model\n",
    "model = IceClassifier(num_classes=CONFIG['num_classes'], pretrained=True)\n",
    "model = model.to(CONFIG['device'])\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nModel: ResNet50 Ice Classifier\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Frozen parameters: {total_params - trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=CONFIG['learning_rate']\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=3, verbose=True\n",
    ")\n",
    "\n",
    "# Metrics tracking\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "print(\"Training setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc='Training')\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Metrics\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Update progress\n",
    "        pbar.set_postfix({\n",
    "            'loss': f\"{loss.item():.4f}\",\n",
    "            'acc': f\"{100. * correct / total:.2f}%\"\n",
    "        })\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    \"\"\"Validate model\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc='Validation'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "print(\"Training functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Starting Training\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(CONFIG['num_epochs']):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{CONFIG['num_epochs']}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, CONFIG['device'])\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, CONFIG['device'])\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nEpoch {epoch + 1} Results:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"  Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.2f}%\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        model_path = f\"{CONFIG['save_dir']}/ice_classifier_notebook.pth\"\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "        }, model_path)\n",
    "        print(f\"  ✅ Saved best model (val_loss: {val_loss:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Complete!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Best val loss: {best_val_loss:.4f}\")\n",
    "print(f\"Best val acc: {max(val_accuracies):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss curves\n",
    "ax1.plot(train_losses, label='Train Loss', marker='o', linewidth=2)\n",
    "ax1.plot(val_losses, label='Val Loss', marker='s', linewidth=2)\n",
    "ax1.set_xlabel('Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Loss', fontsize=12)\n",
    "ax1.set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Accuracy curve\n",
    "ax2.plot(val_accuracies, label='Val Accuracy', marker='o', linewidth=2, color='green')\n",
    "ax2.set_xlabel('Epoch', fontsize=12)\n",
    "ax2.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax2.set_title('Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{CONFIG['save_dir']}/training_curves_notebook.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Training curves saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test Model on Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def test_on_sample(model, dataset, idx=0):\n",
    "    \"\"\"Test model on a single sample\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    image, true_label = dataset[idx]\n",
    "    \n",
    "    # Add batch dimension\n",
    "    image_batch = image.unsqueeze(0).to(CONFIG['device'])\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        output = model(image_batch)\n",
    "        probabilities = torch.softmax(output, dim=1)\n",
    "        predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "        confidence = probabilities[0, predicted_class].item()\n",
    "    \n",
    "    # Class names\n",
    "    class_names = ['Open Water', 'Thin Ice', 'Thick Ice']\n",
    "    \n",
    "    # Visualize\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Image\n",
    "    img_display = image.permute(1, 2, 0).numpy()\n",
    "    ax1.imshow(img_display)\n",
    "    ax1.set_title('Test Image', fontsize=12, fontweight='bold')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Predictions\n",
    "    probs = probabilities[0].cpu().numpy()\n",
    "    bars = ax2.barh(class_names, probs * 100, color=['blue', 'orange', 'green'])\n",
    "    ax2.set_xlabel('Confidence (%)', fontsize=11)\n",
    "    ax2.set_title('Prediction Probabilities', fontsize=12, fontweight='bold')\n",
    "    ax2.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Highlight predicted class\n",
    "    bars[predicted_class].set_color('red')\n",
    "    bars[predicted_class].set_alpha(0.8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nTrue Label: {class_names[true_label]}\")\n",
    "    print(f\"Predicted: {class_names[predicted_class]} ({confidence*100:.1f}% confidence)\")\n",
    "    \n",
    "    if true_label == predicted_class:\n",
    "        print(\"✅ Correct prediction!\")\n",
    "    else:\n",
    "        print(\"❌ Incorrect prediction\")\n",
    "\n",
    "# Test on a few samples\n",
    "for i in range(min(3, len(val_dataset))):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Sample {i}\")\n",
    "    print('='*60)\n",
    "    test_on_sample(model, val_dataset, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save final model\n",
    "final_model_path = f\"{CONFIG['save_dir']}/ice_classifier_final.pth\"\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'config': CONFIG,\n",
    "    'train_losses': train_losses,\n",
    "    'val_losses': val_losses,\n",
    "    'val_accuracies': val_accuracies,\n",
    "}, final_model_path)\n",
    "\n",
    "print(f\"✅ Final model saved to: {final_model_path}\")\n",
    "print(f\"\\nModel Performance:\")\n",
    "print(f\"  Best Val Loss: {min(val_losses):.4f}\")\n",
    "print(f\"  Best Val Accuracy: {max(val_accuracies):.2f}%\")\n",
    "print(f\"\\nTo use this model in production:\")\n",
    "print(f\"  cp {final_model_path} ../../backend/app/models/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "You've successfully trained an ice classification model!\n",
    "\n",
    "**Results**:\n",
    "- Model trained for `{CONFIG['num_epochs']}` epochs\n",
    "- Best validation accuracy: Check output above\n",
    "- Model saved and ready for deployment\n",
    "\n",
    "**Next Steps**:\n",
    "1. Run `03_model_evaluation.ipynb` for detailed evaluation\n",
    "2. Experiment with hyperparameters (learning rate, batch size, epochs)\n",
    "3. Try different model architectures\n",
    "4. Deploy model to backend"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
